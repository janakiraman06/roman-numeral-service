# ============================================
# Spark Configuration for Roman Numeral Lakehouse
# ============================================
# Configures Spark for Iceberg tables on MinIO (S3-compatible)
# with Hive Metastore as the catalog
#
# Compatibility Matrix (verified):
# - Spark: 3.5.0
# - Iceberg: 1.5.2 (iceberg-spark-runtime-3.5_2.12)
# - Hive Metastore: 3.1.3
# - Java: 17 (Bitnami Spark image default)
# ============================================

# Spark SQL Extensions for Iceberg
spark.sql.extensions                                org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions

# Iceberg Catalog Configuration (Hive Metastore)
spark.sql.catalog.lakehouse                         org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.lakehouse.type                    hive
spark.sql.catalog.lakehouse.uri                     thrift://hive-metastore:9083

# Default Catalog
spark.sql.defaultCatalog                            lakehouse

# S3/MinIO Configuration
spark.hadoop.fs.s3a.endpoint                        http://minio:9000
spark.hadoop.fs.s3a.access.key                      minioadmin
spark.hadoop.fs.s3a.secret.key                      minioadmin123
spark.hadoop.fs.s3a.path.style.access               true
spark.hadoop.fs.s3a.impl                            org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.connection.ssl.enabled          false

# Iceberg Write Settings
spark.sql.catalog.lakehouse.io-impl                 org.apache.iceberg.aws.s3.S3FileIO
spark.sql.catalog.lakehouse.s3.endpoint             http://minio:9000
spark.sql.catalog.lakehouse.s3.path-style-access    true

# Spark Streaming Settings
spark.streaming.stopGracefullyOnShutdown            true
spark.streaming.kafka.maxRatePerPartition           1000

# Memory and Performance
spark.executor.memory                               1g
spark.driver.memory                                 1g
spark.sql.shuffle.partitions                        4

# Checkpointing for Structured Streaming
spark.sql.streaming.checkpointLocation              s3a://lakehouse/checkpoints

# ============================================
# OpenLineage Configuration (Data Lineage)
# ============================================
# Emits lineage events to Marquez for data observability
# See: https://openlineage.io/docs/integrations/spark/

spark.extraListeners                                io.openlineage.spark.agent.OpenLineageSparkListener
spark.openlineage.transport.type                    http
spark.openlineage.transport.url                     http://marquez:5000
spark.openlineage.namespace                         rns-lakehouse
spark.openlineage.parentJobName                     spark-etl
spark.openlineage.parentRunId                       ${spark.app.id}

