{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roman Numeral Service - PostgreSQL Exploration\n",
    "\n",
    "This notebook explores the **PostgreSQL OLTP database** used by the Roman Numeral Service.\n",
    "\n",
    "## Architecture Note\n",
    "- **PostgreSQL**: Stores API keys and operational data\n",
    "- **Iceberg Lakehouse**: Stores conversion events (see `02_lakehouse_analysis.ipynb`)\n",
    "\n",
    "## Contents\n",
    "1. Connect to PostgreSQL\n",
    "2. Explore available tables\n",
    "3. API Keys management data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"Libraries loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection\n",
    "DATABASE_URL = \"postgresql://romannumeral:romannumeral_secret@postgres:5432/romannumeral\"\n",
    "\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# Test connection\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT version()\"))\n",
    "    print(f\"Connected to: {result.fetchone()[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all tables\n",
    "tables_query = \"\"\"\n",
    "SELECT table_name \n",
    "FROM information_schema.tables \n",
    "WHERE table_schema = 'public'\n",
    "ORDER BY table_name;\n",
    "\"\"\"\n",
    "\n",
    "tables = pd.read_sql(tables_query, engine)\n",
    "print(\"Available tables:\")\n",
    "display(tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API Keys data\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    id,\n",
    "    key_prefix,\n",
    "    name,\n",
    "    description,\n",
    "    active,\n",
    "    rate_limit_override,\n",
    "    created_at,\n",
    "    last_used_at,\n",
    "    expires_at,\n",
    "    revoked_at\n",
    "FROM api_keys\n",
    "ORDER BY created_at DESC;\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    api_keys_df = pd.read_sql(query, engine)\n",
    "    print(f\"ðŸ“‹ Loaded {len(api_keys_df)} API keys\")\n",
    "    display(api_keys_df)\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading api_keys: {e}\")\n",
    "    print(\"\\nðŸ’¡ The api_keys table may not exist yet.\")\n",
    "    print(\"   API keys are created via the /api/keys endpoint.\")\n",
    "    api_keys_df = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Keys Summary\n",
    "if len(api_keys_df) > 0:\n",
    "    print(\"=\" * 50)\n",
    "    print(\"API KEYS SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Total API keys: {len(api_keys_df):,}\")\n",
    "    print(f\"Active keys: {api_keys_df['active'].sum():,}\")\n",
    "    print(f\"Inactive keys: {(~api_keys_df['active']).sum():,}\")\n",
    "    \n",
    "    if api_keys_df['last_used_at'].notna().any():\n",
    "        print(f\"Last activity: {api_keys_df['last_used_at'].max()}\")\n",
    "    \n",
    "    if api_keys_df['revoked_at'].notna().any():\n",
    "        print(f\"Revoked keys: {api_keys_df['revoked_at'].notna().sum()}\")\n",
    "else:\n",
    "    print(\"No API keys found.\")\n",
    "    print(\"\\nðŸ’¡ To create an API key, run:\")\n",
    "    print('   curl -X POST \"http://localhost:8080/api/keys?name=test-key\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next Steps\n",
    "print(\"=\" * 60)\n",
    "print(\"ðŸ“Š NEXT STEPS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "This notebook explored the PostgreSQL operational database.\n",
    "\n",
    "For conversion analytics, open:\n",
    "    ðŸ““ 02_lakehouse_analysis.ipynb\n",
    "\n",
    "The Lakehouse notebook queries the Iceberg tables:\n",
    "    - lakehouse.bronze.raw_conversion_events (raw Kafka events)\n",
    "    - lakehouse.silver.fact_conversions (cleaned facts)\n",
    "    - lakehouse.gold.popular_numbers (aggregated analytics)\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
