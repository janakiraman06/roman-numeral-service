{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lakehouse Analysis with PySpark\n",
        "\n",
        "This notebook demonstrates querying the Iceberg Lakehouse tables using PySpark.\n",
        "\n",
        "## Medallion Architecture Layers\n",
        "- **Bronze**: Raw events from Kafka (ingested by Flink)\n",
        "- **Silver**: Cleaned, deduplicated facts and SCD Type 2 dimensions\n",
        "- **Gold**: Aggregated metrics for BI/Analytics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Configure Spark for Iceberg on MinIO\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Lakehouse Analysis\") \\\n",
        "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
        "    .config(\"spark.sql.catalog.lakehouse\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
        "    .config(\"spark.sql.catalog.lakehouse.type\", \"hive\") \\\n",
        "    .config(\"spark.sql.catalog.lakehouse.uri\", \"thrift://hive-metastore:9083\") \\\n",
        "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\") \\\n",
        "    .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\") \\\n",
        "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin123\") \\\n",
        "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
        "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark.sparkContext.setLogLevel(\"WARN\")\n",
        "print(f\"Spark version: {spark.version}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List tables in each Medallion layer\n",
        "for db in ['bronze', 'silver', 'gold']:\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"{db.upper()} LAYER TABLES\")\n",
        "    print('='*50)\n",
        "    try:\n",
        "        spark.sql(f\"SHOW TABLES IN lakehouse.{db}\").show(truncate=False)\n",
        "    except Exception as e:\n",
        "        print(f\"Database {db} not found or empty: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query Gold layer - Number popularity\n",
        "try:\n",
        "    popularity = spark.sql(\"\"\"\n",
        "        SELECT \n",
        "            input_value,\n",
        "            total_conversions,\n",
        "            unique_users,\n",
        "            popularity_rank\n",
        "        FROM lakehouse.gold.fact_number_popularity\n",
        "        WHERE popularity_rank <= 20\n",
        "        ORDER BY popularity_rank\n",
        "    \"\"\")\n",
        "    \n",
        "    print(\"Top 20 Most Popular Numbers:\")\n",
        "    popularity.show()\n",
        "except Exception as e:\n",
        "    print(f\"Gold layer not available: {e}\")\n",
        "    print(\"Run the Airflow Gold ETL DAG to populate.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
